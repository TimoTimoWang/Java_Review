
## 负载均衡架构的设计
常见的负载均衡架构的设计通常会选择一个负载均衡器来处理高并发请求，在负载均衡器内部会设计负载均衡算法完成具体的请求分发任务。

常见的负载均衡器的分类：
1. DNS负载均衡
2. 硬件负载均衡
3. 软件负载均衡

### DNS负载均衡
DNS负载均衡通常是根据请求访问的地理位置来缓解服务器的负载，比如当我们访问某个网站时，如果请求的用户的IP地址来源于北方，则返回一个IP地址，将请求分发到集群中的一台服务器中，如果请求的用户的IP地址来源于南方，则返回另外一个IP地址，将请求分发到另一台服务器，从而达到集群负载均衡的目的。

优点：
- 实现简单，只需接入相应的DNS运营商，负载均衡由DNS内部实现，不需要自己额外设计。
- DNS服务器可以防御一定的攻击，比如DOS，DDOS攻击等。
- 可以将请求发送到地理位置最近的服务器，加快访问请求。
缺点：
- 请求分配的粒度太大，高并发场景下单个集群或服务器的负载还是很高。

**适用于做负载均衡的第一层架构设计，根据地理位置分配请求，加快访问速度。**

### 硬件负载均衡
常见的硬件负载均衡有F5和A10，价格昂贵，性能更好，稳定性更高。

优点：
- 性能好，支持百万级别的并发。
- 稳定性更高，经过良好的测试 ，经过大规模的使用，稳定性更高。
缺点：
- 价格昂贵，“土豪级”公司才会使用。

**适用于大规模的并发场景中，在整个架构中担任集群级别的负载均衡器。**

### 软件负载均衡
常见的软件负载均衡有Nginx七层软件负载均衡以及LVS的linux内核四层负载均衡。

优点：
- 便宜：只要部署在廉价的linux服务器上即可。
- 简单灵活：部署简单，并且可以通过业务进行扩展。
缺点：
- 性能一般：一般支持每秒万级别的并发。
- 安全性低：没有防御攻击的能力。
